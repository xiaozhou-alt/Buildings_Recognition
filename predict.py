import numpy as np
import pandas as pd
import cv2
import torch
from torch.utils.data import Dataset, DataLoader
import albumentations as A
from albumentations.pytorch import ToTensorV2
import segmentation_models_pytorch as smp
import os
import re
from tqdm import tqdm

# RLEç¼–è§£ç å‡½æ•°
def rle_encode(im):
    pixels = im.flatten(order='F')
    pixels = np.concatenate([[0], pixels, [0]])
    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1
    runs[1::2] -= runs[::2]
    return ' '.join(str(x) for x in runs)

# é¢„æµ‹ä¸“ç”¨æ•°æ®é›†ç±» - ä¿®æ”¹ä¸ºè¿”å›é«˜åº¦å’Œå®½åº¦ä½œä¸ºå•ç‹¬å€¼
class PredictionDataset(Dataset):
    def __init__(self, file_list, img_dir, transform=None):
        self.file_list = file_list
        self.img_dir = img_dir
        self.transform = transform
        
    def __len__(self):
        return len(self.file_list)
    
    def __getitem__(self, idx):
        # åªè·å–æ–‡ä»¶åéƒ¨åˆ†ï¼ˆç¬¬ä¸€åˆ—ï¼‰
        full_line = self.file_list[idx]
        filename = full_line.split('\t')[0].strip()
        
        img_path = os.path.join(self.img_dir, filename)
        
        # è¯»å–å›¾åƒ
        image = cv2.imread(img_path)
        if image is None:
            # å°è¯•æ·»åŠ .jpgæ‰©å±•å
            if not filename.lower().endswith(('.jpg', '.jpeg')):
                img_path_with_ext = os.path.join(self.img_dir, filename + '.jpg')
                image = cv2.imread(img_path_with_ext)
                if image is not None:
                    print(f"âš ï¸ ä¿®æ­£æ–‡ä»¶å: {filename} -> {filename}.jpg")
                    filename = filename + '.jpg'
                    img_path = img_path_with_ext
        
        if image is None:
            print(f"âŒ æ— æ³•è¯»å–å›¾åƒ: {img_path}")
            # åˆ›å»ºæ›¿ä»£å›¾åƒ
            image = np.zeros((512, 512, 3), dtype=np.uint8)
            height, width = 512, 512
        else:
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            height, width = image.shape[:2]
        
        if self.transform:
            augmented = self.transform(image=image)
            image = augmented['image']
        
        # è¿”å›é«˜åº¦å’Œå®½åº¦ä½œä¸ºå•ç‹¬å€¼
        return image, filename, height, width

# é¢„æµ‹è½¬æ¢é…ç½®
def get_prediction_transform():
    return A.Compose([
        A.Resize(384, 384),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])

def main():
    # é…ç½®å‚æ•°
    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    BATCH_SIZE = 4
    MODEL_PATH = './output/model/best_model.pth'
    TEST_A_DIR = './data/test_a'
    SUBMISSION_FILE = './data/test_a_samplesubmit.csv'
    OUTPUT_CSV = 'test_a_samplesubmit.csv'
    
    print("="*50)
    print(f"ğŸš€ å¼€å§‹å»ºç­‘ç‰©åˆ†å‰²é¢„æµ‹")
    print(f"ğŸ“Œ è®¾å¤‡: {DEVICE}")
    print(f"ğŸ“Š æ‰¹æ¬¡å¤§å°: {BATCH_SIZE}")
    print(f"ğŸ–¼ï¸ æµ‹è¯•å›¾ç‰‡æ–‡ä»¶å¤¹: {TEST_A_DIR}")
    print(f"ğŸ“„ æäº¤æ ·æœ¬æ–‡ä»¶: {SUBMISSION_FILE}")
    print("="*50)
    
    # è¯»å–æäº¤æ ·æœ¬æ–‡ä»¶
    print("ğŸ“‚ è¯»å–æäº¤æ ·æœ¬æ–‡ä»¶...")
    with open(SUBMISSION_FILE, 'r') as f:
        submission_lines = [line.strip() for line in f.readlines()]
    
    # åˆ›å»ºæ•°æ®é›†
    print("\nğŸ–¼ï¸ åˆ›å»ºé¢„æµ‹æ•°æ®é›†...")
    transform = get_prediction_transform()
    prediction_dataset = PredictionDataset(
        file_list=submission_lines,
        img_dir=TEST_A_DIR,
        transform=transform
    )
    
    prediction_loader = DataLoader(
        prediction_dataset, 
        batch_size=BATCH_SIZE, 
        shuffle=False,
        num_workers=2
    )
    
    # åŠ è½½æ¨¡å‹
    print("\nğŸ›  åŠ è½½æ¨¡å‹...")
    model = smp.Unet(
        encoder_name='efficientnet-b4',
        encoder_weights=None,
        in_channels=3,
        classes=1,
        activation=None
    ).to(DEVICE)
    
    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))
    model.eval()
    print("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
    
    # è¿›è¡Œé¢„æµ‹ï¼ˆä¿®æ”¹åçš„éƒ¨åˆ†ï¼‰
    print("\nğŸ”® å¼€å§‹é¢„æµ‹...")
    results = []
    
    with torch.no_grad():
        for batch in tqdm(prediction_loader, desc="é¢„æµ‹ä¸­"):
            images = batch[0].to(DEVICE)
            filenames = batch[1]
            heights = batch[2]  # é«˜åº¦åˆ—è¡¨
            widths = batch[3]   # å®½åº¦åˆ—è¡¨
            
            outputs = model(images)
            preds = torch.sigmoid(outputs) > 0.5
            
            for i in range(len(filenames)):
                h = heights[i].item() if torch.is_tensor(heights[i]) else heights[i]
                w = widths[i].item() if torch.is_tensor(widths[i]) else widths[i]
                
                pred_mask = preds[i].squeeze().cpu().numpy().astype(np.uint8)
                resized_mask = cv2.resize(pred_mask, (w, h), interpolation=cv2.INTER_NEAREST)
                
                rle = rle_encode(resized_mask) if np.sum(resized_mask) > 0 else ""
                results.append((filenames[i], rle))
    
    # ä¿å­˜ç»“æœ
    print("\nğŸ’¾ ä¿å­˜é¢„æµ‹ç»“æœ...")
    with open(OUTPUT_CSV, 'w') as f:
        for i, (filename, rle) in enumerate(results):
            original_filename = submission_lines[i].split('\t')[0].strip()
            f.write(f"{original_filename}\t{rle}\n")
    
    print(f"âœ… é¢„æµ‹ç»“æœå·²ä¿å­˜è‡³: {OUTPUT_CSV}")
    
    # æ‰“å°ç»“æœç»Ÿè®¡
    print("\né¢„æµ‹ç»“æœç¤ºä¾‹:")
    for i in range(min(5, len(results))):
        print(f"{results[i][0]}\t{results[i][1]}")
    
    empty_count = sum(1 for _, rle in results if rle == "")
    print(f"\næ— å»ºç­‘ç‰©çš„å›¾ç‰‡æ•°é‡: {empty_count}/{len(results)}")

if __name__ == '__main__':
    main()